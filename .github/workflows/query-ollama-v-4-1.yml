name: Install and Run Ollama v4

on:
  workflow_dispatch:
    inputs:
      model:
        description: 'The model to run with Ollama (e.g., llama3.1)'
        required: true
        default: 'llama3.1'
      prompt:
        description: 'The prompt to query the model'
        required: true
        default: 'Hello world!'

permissions:
  contents: read

jobs:
  run_ollama:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Install Ollama if not cached
      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh

      # Run Ollama server in the background
      - name: Run Ollama server in the background
        run: |
          nohup ollama serve & # Start Ollama server in the background
          sleep 10 # Give it some time to start

      # Run the specified model using the 'model' input
      - name: Run llama model
        run: |
          ollama run ${{ github.event.inputs.model }}

      # Set up Go environment
      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.20' # Adjust the version as needed

      # Build Go script
      - name: Build Go script
        run: |
          go build -o query-ollama query-ollama.go

      # Make Go script executable
      - name: Make Go script executable
        run: |
          chmod +x query-ollama

      # Run Go script
      - name: Run Go script
        run: |
          ./query-ollama -model "${{ github.event.inputs.model }}" -prompt "${{ github.event.inputs.prompt }}"
