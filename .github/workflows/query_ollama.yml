name: Install and Run Ollama

on:
    workflow_dispatch: # Allows running this workflow manually from the Actions tab

permissions:
    contents: read

jobs:
    run_ollama:
        runs-on: ubuntu-latest

        steps:
            - name: Install Ollama
              run: |
                  curl -fsSL https://ollama.com/install.sh | sh

            - name: Run Ollama server in the background
              run: |
                  nohup ollama serve & # Start Ollama server in the background
                  sleep 10 # Give it some time to start

            - name: Run llama model
              run: |
                  ollama run llama3.1

            - name: Generate response from Ollama
              run: |
                  curl http://localhost:11434/api/generate -d '{
                    "model": "llama3.1",
                    "prompt":"Why is the sky blue? Respond with a very short answer."
                  }'
